# üå∏ Little Helper - Your Personal AI Assistant

A beautiful AI assistant that gives you control over your privacy. Chat with your personal AI to find files, get tech support, and research topics - choose between fully local processing or powerful cloud models.

## ‚ú® Features
- **üîç Find Mode**: Ask your AI to find any file on your Mac, Google Drive, or connected drives
- **üîß Fix Mode**: Get personalized tech support and troubleshooting help
- **üîå Research Mode**: Have conversations about any topic with your AI
- **üé® Beautiful Design**: Modern, rounded interface with soft colors
- **üîí Privacy Options**: Choose fully local processing (Ollama) or cloud models (OpenAI, Anthropic, Gemini)
- **ü§ñ Smart Conversations**: Real back-and-forth chat with context memory

## üöÄ One-Click Installation (macOS)

Just run this single command in Terminal:

```bash
curl -fsSL https://raw.githubusercontent.com/M0nkeyFl0wer/claudia-lite/main/install-mac.sh | bash
```

This automatically installs:
- ‚úÖ Little Helper app in Applications
- ‚úÖ Local AI engine (Ollama) for privacy-focused operation
- ‚úÖ Smart AI model (3GB, optimized for conversations)
- ‚úÖ Optional: Configure cloud providers (OpenAI, Anthropic, Gemini) in settings

## üéØ How to Use

1. **Open Little Helper** from Applications
2. **Choose your mode**: Find, Fix, or Research  
3. **Start chatting!** Ask questions naturally like:
   - "Find my tax documents from 2023"
   - "My WiFi is acting up, can you help?"
   - "Tell me about sustainable gardening"

Your AI remembers the conversation context and asks follow-up questions to better help you!

## üîê AI Provider Configuration

Little Helper supports multiple AI providers, giving you complete control over privacy and capabilities:

### Local-Only (Default - Maximum Privacy)
By default, Little Helper uses **Ollama** for completely local AI processing. Your data never leaves your computer.

No configuration needed! Just install using the installer above.

### Cloud Providers (Optional - More Powerful)
You can optionally configure cloud AI providers for enhanced capabilities.

**‚ö†Ô∏è Important:** These providers require **API accounts** with pay-per-use billing. This is **separate** from ChatGPT Plus, Claude Pro, or Gemini Advanced subscriptions.

#### Setting Up API Access (Recommended Method)

**OpenAI**
```bash
export OPENAI_API_KEY="your-api-key-here"
```
Get your API key from: https://platform.openai.com/api-keys
(Separate from ChatGPT Plus - requires OpenAI API account)

**Anthropic (Claude)**
```bash
export ANTHROPIC_API_KEY="your-api-key-here"
```
Get your API key from: https://console.anthropic.com/settings/keys
(Separate from Claude Pro - requires Anthropic API account)

**Google Gemini**
```bash
export GEMINI_API_KEY="your-api-key-here"
```
Get your API key from: https://aistudio.google.com/app/apikey
(Separate from Gemini Advanced - uses Gemini API)

#### OAuth Authentication (Advanced - Like Cline in VS Code)

Little Helper supports OAuth browser flows similar to Cline/Continue.dev. The infrastructure is ready, but requires creating OAuth applications:

- **Anthropic**: No public OAuth (enterprise only)
- **Google**: Requires Google Cloud Console setup
- **OpenAI**: No OAuth for API access

**For most users, API keys are simpler.**

### Provider Priority
Edit your settings file (`~/.config/Little Helper/LittleHelper/settings.json`) to configure provider fallback:

```json
{
  "model": {
    "provider_preference": ["local", "openai", "anthropic", "gemini"]
  }
}
```

The app will try each provider in order until one succeeds. For maximum privacy, use `["local"]` only.

## üõ†Ô∏è Developer Setup

If you want to build from source:
```bash
# Prerequisites: Rust toolchain + Ollama running locally
cargo run -p app
```
